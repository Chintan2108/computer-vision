{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Applications for Videos\n",
    "\n",
    "Through out the course we have discussed various CV applications both in the traditional CV space as well as the deep learning space. This notebook discusses some relatively new applications in these spaces for videos. \n",
    "\n",
    "This notebook presents an overview of some intereseting applications to analyze or process videos using computer vision techniques. Along with videos, this notebook also presents some worthy real time applications of CV. These are not neccessarily for video data but on a stream of images. \n",
    "\n",
    "Let's look at these applications and try to understand the concepts behind them on a high level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV for Videos\n",
    "\n",
    "We have seen how we can analyse videos using image processing techniques, by processing one frame at a time. But in those techniques we do not leverage the relationship which consecutive frames of the video have.\n",
    "\n",
    "As we know that a video is a sequence of a large number of frames, thus these video frames are temporally related to each other. This relation manifests in both in the form of temporal redundancies as well as logical temporal relationship between the frames.\n",
    "\n",
    "**Example**: a video of a car on a highway will have frames showing the car progressing in a particular direction as we progress forward in the frame sequence.\n",
    "\n",
    "**This temporal nature of the video makes them a good candidate input for sequential models such as RNN and LSTMs for sequential analysis.**\n",
    "\n",
    "Let us see some examples of cv applied to video data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Classification\n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    "\n",
    "Video classification is simply the categorization of a video into defined categories. This problem is similar to image classification but only with increased complexity due to the fact a video is a collection of several hundreds or thousands of frames and also that these images might be different from each other although belonging to a single category.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"http://blog.qure.ai/assets/images/actionrec/fronststroke.gif\" width = 200px/>\n",
    "    <figcaption style = \"text-align:center\">Front Stroke. Ref: \n",
    "        <a href=\"http://blog.qure.ai/notes/deep-learning-for-videos-action-recognition-review\">Deep Learning for Videos: A 2018 Guide to Action Recognition</a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"http://blog.qure.ai/assets/images/actionrec/breaststroke.gif\" width = 200px/>\n",
    "    <figcaption style = \"text-align:center\">Breast Stroke. Ref: \n",
    "        <a href=\"http://blog.qure.ai/notes/deep-learning-for-videos-action-recognition-review\">Deep Learning for Videos: A 2018 Guide to Action Recognition</a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Datasets**:\n",
    "\n",
    "- [Sports 1M Dataset](https://github.com/gtoderici/sports-1m-dataset/): provides links to 1,133,158 YouTube videos annotated with 487 sports labels. The annotations were generated automatically using the the YouTube Topics, which has a public API.\n",
    "- [UCF 101 - Action Recognition Dataset](https://www.crcv.ucf.edu/data/UCF101.php): UCF101 is an action recognition data set of realistic action videos, collected from YouTube, having 101 action categories. \n",
    "\n",
    "**Approaches**:\n",
    "\n",
    "- Classifying each frame of a video using a 2D CNN and then averaging the predictions.\n",
    "- Using a 3D CNN to perform convolution on a set of frames.\n",
    "- Extracting features for each frame using 2D CNN in a time distributed manner and then feeding the features to an RNN\n",
    "\n",
    "**Interesting Reads**:\n",
    "\n",
    "- https://www.pyimagesearch.com/2019/07/15/video-classification-with-keras-and-deep-learning/\n",
    "- https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42455.pdf\n",
    "- http://blog.qure.ai/notes/deep-learning-for-videos-action-recognition-review\n",
    "- https://www.youtube.com/watch?v=PrPv9GV1jPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Captioning/Description\n",
    "\n",
    "**Problem Statement**\n",
    "\n",
    "Video captioning/description is an interesting intersection area of CV and NLP. It refers to generation of a sequence of text which describes a sequence of frames. This problem brings with it a very challenging aspect of learning the spatio-temporal dependencies in video frames and learn their mapping with the sequential representation of text.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"https://github.com/AdrianHsu/S2VT-seq2seq-video-captioning-attention/raw/master/util/s2vt-1.png\" width = 900px/>\n",
    "    <figcaption style = \"text-align:center\">Image showing a Seq2Seq model for video captioning. Ref: \n",
    "        <a href=\"https://github.com/AdrianHsu/S2VT-seq2seq-video-captioning-attention\">S2VT</a>\n",
    "    </figcaption>\n",
    "</figure>\n",
    "\n",
    "<br/>\n",
    "\n",
    "**Aproaches**\n",
    "\n",
    "- Seq2Seq Models\n",
    "- Attention Models\n",
    "\n",
    "**Interesting Reads**\n",
    "\n",
    "- https://github.com/DataScienceNigeria/AI-powered-by-Google-s-VideoBERT-\n",
    "- https://github.com/AdrianHsu/S2VT-seq2seq-video-captioning-attention\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
